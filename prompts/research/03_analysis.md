# Analysis & Synthesis Templates

Convert raw notes into defendable insights using structured thinking and explicit evidence mapping.

## 1. Claims → Evidence Map
| Claim ID | Draft Claim | Supporting Evidence | Evidence Grade | Confidence | Notes / Follow-Up |
|----------|-------------|---------------------|----------------|------------|-------------------|
| C1 | | Source IDs, quotes, data points | A/B/C/D | High/Med/Low | Gaps, caveats, validation needed |

**How to use**
1. Convert each preliminary insight into a neutral claim statement.
2. Link every claim to at least two evidence entries; note publication date to highlight freshness.
3. Evaluate whether the evidence supports, partially supports, or contradicts the claim.
4. Capture follow-up actions (e.g., "Need primary source" or "Confirm with SME").

### Thematic Synthesis Grid
| Theme | Key Claims | Evidence Highlights | Counterpoints | Decision Impact |
|-------|------------|---------------------|---------------|-----------------|
| | | | | |

## 2. Analytical Prompts
- **Pattern spotting**: "What consistent behaviors or data points recur across the highest-grade sources?"
- **Drivers & inhibitors**: "Which factors accelerate or block adoption, and which stakeholders care most?"
- **Comparative lens**: "How does this topic differ across industries, geographies, or maturity tiers?"
- **Temporal dimension**: "How have claims evolved over the past 12/24 months? What signals future change?"

## 3. Risk & Bias Flags
- **Recency risk**: Are we relying on sources older than the decision window requires?
- **Vendor bias**: Does the evidence come primarily from parties with a commercial stake?
- **Survivorship bias**: Are failure modes underrepresented relative to success stories?
- **Data quality**: Are methodologies transparent, sample sizes adequate, and metrics comparable?
- **Confirmation bias**: Are contradictory sources dismissed or weighted fairly?
- **Automation bias**: Were any AI-generated summaries accepted without manual verification?

Log each flag with a mitigation plan in the research notebook.

## 4. Counter-Argument Playbook
1. **State the opposing position** in its strongest form.
2. **List evidence** that could support the counter-claim, even if not yet gathered.
3. **Assess exposure**: what would change if the counter-claim were true?
4. **Plan validation**: design a quick test (expert interview, additional dataset) to probe the counter-claim.
5. **Decide**: incorporate the counter-argument into findings, mark as unresolved, or deprioritize with justification.

### Counter-Argument Prompts
- "Who benefits if this claim is wrong?"
- "What is the most credible source disagreeing with our stance?"
- "Which assumption would cause the largest downstream failure if invalidated?"
- "How would a risk officer or auditor critique this recommendation?"

## 5. Deliverable-Ready Storyboard
- **Executive hook**: 2–3 sentences that connect the topic to stakeholder goals.
- **Evidence pillars**: top three claims with the highest confidence and impact.
- **Risk disclosures**: articulate uncertainties or caveats with mitigation ideas.
- **Next actions**: decision options, experiments, or research extensions.

Use the storyboard as the blueprint when transferring insights into the reporting template.
