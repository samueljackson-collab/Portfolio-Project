# PRJ-AIML-002 — Intelligent Automation Playbooks

## Project Overview
This initiative codifies how the automation team deploys AI/ML-driven workflows into production for operational teams. It documents intake requirements, human-in-the-loop checkpoints, rollback plays, and the instrumentation needed to prove value once the automation is live.

## Deliverables
- Business intake form with automated triage rules.
- Fine-tuned model deployment pipeline with governance checkpoints.
- n8n workflow templates for orchestration, notifications, and ticketing.
- Observability pack: Matomo dashboards, warehouse queries, and Slack alerts for post-launch monitoring.

## Success Metrics & Post-Launch Optimization
The following key performance indicators (KPIs) ensure we monitor both system health and business value once the automations are in production.

| Metric | Data Source | Dashboard/Query | Update Frequency | Owner | Alert Threshold |
| --- | --- | --- | --- | --- | --- |
| **Automation Success Rate (Technical)** | Matomo custom events `automation_run_success` / `automation_run_failed` | Matomo Dashboard **Automation Reliability** → Custom Report `Events.getCategory` with segment `eventCategory=="automation_run"` (API: `?module=API&method=Events.getCategory&idSite=7&period=day&date=today&segment=eventCategory==automation_run`) | Hourly pull via Matomo scheduled report → n8n webhook | Analytics Engineer | < 95% success over last 6 hours triggers alert |
| **Inference Latency P95 (Technical)** | n8n workflow log table `wf_inference_latency` (PostgreSQL) | External report **Latency Deep Dive** generated by dbt model `models/latency/p95_latency.sql` surfaced in Metabase dashboard card `#78` (SQL ref: `SELECT run_at, p95_ms FROM mart_inference_latency ORDER BY run_at DESC LIMIT 288`) | Every 15 minutes via dbt Cloud job | MLOps Lead | > 1500 ms P95 latency for two consecutive runs |
| **Retraining Job Health (Technical)** | n8n workflow `wf_model_retrain` execution history + Matomo event `model_retrain_complete` | Matomo Dashboard **Model Lifecycle** widget `Scheduled Tasks Status` (API: `?module=API&method=ScheduledReports.generateReport&idReport=21`) with cross-check to n8n dashboard card `wf_model_retrain` | Daily at 02:00 UTC | MLOps Lead | Any missed daily retrain or run duration > 2× baseline |
| **Automated Tickets Resolved (Business)** | Zendesk exports ingested via n8n workflow `wf_zendesk_closed_tickets` → warehouse table `fact_ticket_resolution` | Metabase dashboard **Automation Impact** card `#105` (SQL: `SELECT week_start, automated_resolved, manual_resolved FROM fact_ticket_resolution_weekly`) with Matomo Goal `automation_ticket_resolved` overlay | Daily 06:00 UTC refresh | Customer Ops Manager | < 250 automated resolutions per week or week-over-week drop > 15% |
| **Cycle Time Reduction (Business)** | Matomo custom dimension `automation_cycle_time` captured via event timers + Google Sheets benchmark data | Matomo Dashboard **Efficiency KPIs** panel `Custom Dimensions > automation_cycle_time` (API: `?module=API&method=CustomDimensions.getCustomDimension&idDimension=3&idSite=7&period=week&date=last4`) with external Google Looker Studio report **Ops Cycle Baseline** blending Sheet `automation_baseline!A:D` | Weekly (Monday 12:00 UTC) | Analytics Engineer | < 20% reduction vs. baseline for 2 consecutive weeks |
| **Cost Avoidance (Business)** | Finance export `automation_costs.csv` processed via n8n `wf_finance_cost_avoidance` to warehouse table `mart_cost_avoidance` | Looker Studio report **Automation ROI Tracker** tile `Cost Avoidance vs. Target` (SQL: `SELECT month, cost_avoided, target FROM mart_cost_avoidance_monthly`) with Matomo KPI tile `Goal.get` for goal `automation_roi` | Monthly (1st business day) | Finance Partner | < 90% of target for current quarter |

### Alerting & Incident Response Flow
1. Matomo scheduled reports (Automation Reliability, Model Lifecycle, Efficiency KPIs) push JSON payloads to the n8n webhook `https://automations.example.com/webhooks/matomo_kpi_ingest`.
2. n8n workflow `wf_kpi_guardrails` validates payloads against the thresholds above, enriches context with latest warehouse metrics via PostgreSQL node (`SELECT * FROM kpi_thresholds WHERE metric_key = $json.metric_key`), and branches alerts based on severity.
3. Critical breaches post to Slack channel `#automation-alerts` via Slack node with incident template, create Jira issue `AUTOMATION` project via Jira node, and page on-call via Opsgenie integration. Warning-level breaches create a Slack thread and append to the shared Confluence runbook.
4. Workflow audit trail is written back to the `fact_kpi_alerts` table for retrospective analysis and to confirm alert closure SLAs.

### Weekly Optimization Rituals
- **Monday 15:00 UTC – KPI Review Sync (Analytics Engineer-led):** Walk through Matomo dashboards and Looker Studio ROI tracker, triage open alerts from `fact_kpi_alerts`, and assign owners for remediation actions.
- **Wednesday 16:00 UTC – Automation Engineering Standup:** MLOps Lead reviews retraining job health and latency cards, confirming backlog and Jira tickets are on track.
- **Friday 14:00 UTC – Ops Feedback Loop:** Customer Ops Manager presents Zendesk automation outcomes, captures qualitative feedback, and ensures insights are logged in the Confluence automation playbook.
- Dashboard owners document decisions and follow-up items in the shared meeting notes (`/docs/automation/kpi-reviews.md`) to maintain auditability and continuous improvement.
