# Prometheus Configuration for Homelab Observability Stack
# =========================================================
# 
# DEPLOYMENT INFORMATION:
# -----------------------
# Expected location: /etc/prometheus/prometheus.yml
# Validation command: promtool check config prometheus.yml
# Service reload: sudo systemctl reload prometheus
# 
# DIRECTORY STRUCTURE:
# --------------------
# /etc/prometheus/
#   ├── prometheus.yml (this file)
#   ├── alerts/
#   │   └── infrastructure_alerts.yml
#   ├── rules/
#   │   └── [recording rules here]
#   └── secrets/
#       ├── proxmox_exporter.password
#       └── truenas_exporter.password
#
# SECURITY NOTES:
# ---------------
# Basic auth credentials in this file are PLACEHOLDERS for demonstration.
# In production environments, use one of these approaches:
#   1. Password files: password_file: /etc/prometheus/secrets/<service>.password
#   2. Environment variables with configuration templating
#   3. Secret management systems (Vault, AWS Secrets Manager, etc.)
# Never commit real credentials to version control.
#
# -----------------------------------------------------------

global:
  # Scrape all targets every 15 seconds to capture fine-grained metrics
  # while balancing resource usage on the small homelab environment.
  scrape_interval: 15s
  
  # Evaluate alerting and recording rules at the same cadence as scraping so
  # the latest data is always used for alert calculations.
  evaluation_interval: 15s
  
  # Scrape timeout is set to 10 seconds (66% of scrape_interval), following
  # industry best practice. This provides a 5-second buffer before the next
  # scrape begins, preventing overlapping scrapes and resource contention.
  # The timeout MUST always be less than scrape_interval.
  scrape_timeout: 10s
  
  # Global labels added to every time series. These make it easy to filter all
  # data from this homelab cluster when federating or aggregating metrics.
  external_labels:
    environment: homelab
    cluster: main

# Alerting configuration defines how Prometheus sends alerts to Alertmanager.
alerting:
  alert_relabel_configs:
    # Derive severity labels dynamically based on alert names to simplify rule
    # definitions. This relabeling strategy ensures consistent severity labels
    # across all alerts before they reach Alertmanager, enabling efficient
    # routing based on the severity-based routing tree defined in alertmanager.yml.
    # The Alertmanager routes (email for critical, PagerDuty for critical,
    # Slack for warning/info) depend on these severity labels.
    - source_labels: [alertname]
      regex: ".*(Critical|Severe).*"
      target_label: severity
      replacement: critical
    - source_labels: [alertname]
      regex: ".*(Warn|High|Warning).*"
      target_label: severity
      replacement: warning
    - source_labels: [alertname]
      regex: ".*(Info|Informational).*"
      target_label: severity
      replacement: info
  alertmanagers:
    - static_configs:
        # Alertmanager runs on the same host as Prometheus, reachable via the
        # loopback interface. TLS can be added later if exposed remotely.
        - targets: ['localhost:9093']
      # Timeout for sending alerts to Alertmanager. A short timeout prevents
      # metric pipeline interruptions if Alertmanager is unavailable.
      timeout: 10s

# Rule files containing alerting and recording rules.
# -----------------------------------------------------
# Alert rules are defined in infrastructure_alerts.yml and include:
#   - Node health checks (node exporter down, high CPU/memory/disk)
#   - Proxmox infrastructure alerts (VM down, cluster issues)
#   - TrueNAS storage alerts (SMART failures, capacity warnings)
# 
# The glob patterns allow multiple rule files to be dropped into these
# directories without updating this configuration.
rule_files:
  - /etc/prometheus/alerts/*.yml
  - /etc/prometheus/rules/*.yml

# Scrape configuration section enumerates every target monitored in the homelab.
# -------------------------------------------------------------------------------
# All scrape configs follow a consistent pattern:
#   - Explicit hostname labels for dashboard/alert clarity
#   - 15-second scrape intervals (matching global default)
#   - 10-second timeouts (66% of interval)
#   - Standardized metric relabeling for instance labels
#
# For scaling beyond static IPs, consider file-based service discovery:
#   file_sd_configs:
#     - files: ['targets/*.json']
#       refresh_interval: 30s

scrape_configs:
  # =========================================================================
  # PROMETHEUS SELF-MONITORING
  # =========================================================================
  - job_name: prometheus
    scrape_interval: 15s
    scrape_timeout: 10s
    static_configs:
      - targets: ['localhost:9090']
        labels:
          hostname: prom-main
          job: prometheus
    metric_relabel_configs:
      # Standardize instance label to hostname:port format for consistency
      # across dashboards and alert queries.
      - source_labels: [instance]
        target_label: instance
        replacement: prom-main:9090

  # =========================================================================
  # NODE EXPORTER - PROXMOX HYPERVISOR
  # =========================================================================
  - job_name: proxmox-node
    scrape_interval: 15s
    scrape_timeout: 10s
    scheme: http
    static_configs:
      - targets: ['192.168.1.10:9100']
        labels:
          hostname: proxmox-host
          job: node-exporter
    # Basic auth credentials are PLACEHOLDERS. In production, use:
    #   password_file: /etc/prometheus/secrets/proxmox_node.password
    basic_auth:
      username: proxmox_exporter
      password: changeme
    metric_relabel_configs:
      # Ensure consistent instance labeling across all node exporter targets
      - source_labels: [hostname]
        separator: ':'
        regex: '(.*)'
        target_label: instance
        replacement: '${1}:9100'

  # =========================================================================
  # NODE EXPORTER - VIRTUAL MACHINES
  # =========================================================================
  - job_name: vm-nodes
    scrape_interval: 15s
    scrape_timeout: 10s
    static_configs:
      - targets:
          - '192.168.1.20:9100'
          - '192.168.1.21:9100'
          - '192.168.1.22:9100'
          - '192.168.1.23:9100'
          - '192.168.1.24:9100'
        labels:
          job: node-exporter
    relabel_configs:
      # Attach friendly hostnames used across dashboards and alerts.
      # This mapping should be kept in sync with DNS/DHCP reservations.
      - source_labels: [__address__]
        regex: '192.168.1.(20):.*'
        replacement: vm-wiki
        target_label: hostname
      - source_labels: [__address__]
        regex: '192.168.1.(21):.*'
        replacement: vm-homeassistant
        target_label: hostname
      - source_labels: [__address__]
        regex: '192.168.1.(22):.*'
        replacement: vm-immich
        target_label: hostname
      - source_labels: [__address__]
        regex: '192.168.1.(23):.*'
        replacement: vm-db
        target_label: hostname
      - source_labels: [__address__]
        regex: '192.168.1.(24):.*'
        replacement: vm-utility
        target_label: hostname
    metric_relabel_configs:
      # Standardize instance labels to use hostname:port format, matching
      # the pattern established by the proxmox-node job.
      - source_labels: [hostname]
        separator: ':'
        regex: '(.*)'
        target_label: instance
        replacement: '${1}:9100'

  # =========================================================================
  # ALERTMANAGER
  # =========================================================================
  - job_name: alertmanager
    scrape_interval: 15s
    scrape_timeout: 10s
    static_configs:
      - targets: ['localhost:9093']
        labels:
          job: alertmanager
          hostname: alertmanager-main
    metric_relabel_configs:
      # Apply consistent instance labeling pattern
      - source_labels: [hostname]
        separator: ':'
        regex: '(.*)'
        target_label: instance
        replacement: '${1}:9093'

  # =========================================================================
  # PROXMOX EXPORTER
  # =========================================================================
  # Exposes metrics for all Proxmox VMs and containers, including resource
  # usage, state transitions, and cluster health.
  - job_name: proxmox-exporter
    scrape_interval: 15s
    scrape_timeout: 10s
    static_configs:
      - targets: ['192.168.1.10:9221']
        labels:
          job: proxmox-exporter
          hostname: proxmox-host
    # Basic auth credentials are PLACEHOLDERS. In production, use:
    #   password_file: /etc/prometheus/secrets/proxmox_exporter.password
    basic_auth:
      username: proxmox_exporter
      password: changeme
    metric_relabel_configs:
      # Apply consistent instance labeling pattern
      - source_labels: [hostname]
        separator: ':'
        regex: '(.*)'
        target_label: instance
        replacement: '${1}:9221'

  # =========================================================================
  # TRUENAS EXPORTER
  # =========================================================================
  # Provides storage metrics, capacity utilization, pool health, and SMART
  # drive diagnostics from the TrueNAS storage system.
  - job_name: truenas-exporter
    scrape_interval: 15s
    scrape_timeout: 10s
    static_configs:
      - targets: ['192.168.1.5:9273']
        labels:
          job: truenas-exporter
          hostname: truenas-core
    # Basic auth credentials are PLACEHOLDERS. In production, use:
    #   password_file: /etc/prometheus/secrets/truenas_exporter.password
    basic_auth:
      username: truenas_exporter
      password: changeme
    metric_relabel_configs:
      # Apply consistent instance labeling pattern
      - source_labels: [hostname]
        separator: ':'
        regex: '(.*)'
        target_label: instance
        replacement: '${1}:9273'