# PostgreSQL - Centralized Database Server
# =========================================
# Version: PostgreSQL 16.1 (Latest stable)
# Platform: Ubuntu 22.04 LTS VM (VM ID: 103)
# Resources: 4 vCPU, 16GB RAM, 200GB Disk
# Network: 192.168.40.23/24 (VLAN 40 - Lab Network)
# Clients: Wiki.js, Home Assistant, Immich
#
# This is a centralized PostgreSQL instance serving multiple homelab services.
# Running a single database VM (instead of per-service databases) provides:
# - Resource efficiency (shared memory, connection pooling)
# - Simplified backup strategy (one database to backup)
# - Centralized monitoring and performance tuning
# - Easier disaster recovery (restore one VM, recover all services)
#
# Architecture Decision: Shared vs. Dedicated Databases
# ------------------------------------------------------
# Shared Database Approach (this deployment):
#  Lower resource usage (one Postgres instance vs. 3+)
#  Simplified backups (one pg_dump for all databases)
#  Easier monitoring (one database to monitor)
#  Cost effective (one VM license/patch cycle)
#  Single point of failure (outage affects all services)
#  Resource contention (one service can starve others)
#
# Mitigation strategies:
# - Resource limits per database (prevent one service from consuming all RAM)
# - Connection pooling (pgBouncer to limit total connections)
# - High availability (future: streaming replication to standby server)
# - Regular backups with tested restore procedure
#
# Databases Hosted:
# -----------------
# 1. wikijs - Wiki.js knowledge base
#    - Estimated size: 500MB (typical for 500 pages)
#    - Connection pool: 10 connections
#    - Workload: Light (primarily reads, writes on page edits)
#
# 2. homeassistant - Home Assistant history/recorder
#    - Estimated size: 5GB (30 days retention, 50 devices)
#    - Connection pool: 20 connections
#    - Workload: Heavy writes (continuous sensor data), moderate reads
#    - Optimization: Aggressive purging (7-14 day retention recommended)
#
# 3. immich - Immich photo metadata and search
#    - Estimated size: 2GB (10,000 photos with ML metadata)
#    - Connection pool: 15 connections
#    - Workload: Moderate writes (photo uploads), heavy reads (search/browse)
#
# Total estimated size: 10GB (20GB with indexes and overhead)
# 200GB disk allocation allows 20x growth headroom
#
# Prerequisites:
# ==============
# 1. Ubuntu 22.04 LTS VM deployed in Proxmox
# 2. Static IP configured: 192.168.40.23/24
# 3. Firewall rules:
#    - Allow 5432/tcp from 192.168.40.0/24 (Lab VLAN)
#    - Deny 5432/tcp from all other networks
# 4. Directory structure:
#    mkdir -p /opt/postgresql/data
#    mkdir -p /opt/postgresql/backups
#    chown -R 999:999 /opt/postgresql/data  # UID 999 = postgres user in container
#
# Deployment:
# ===========
#   docker-compose up -d
#
# Initial Setup:
# ==============
# 1. Wait for container to initialize (30 seconds)
# 2. Create databases for each service:
#    docker exec -it postgres psql -U postgres -c "CREATE DATABASE wikijs;"
#    docker exec -it postgres psql -U postgres -c "CREATE DATABASE homeassistant;"
#    docker exec -it postgres psql -U postgres -c "CREATE DATABASE immich;"
# 3. Create users with passwords from .env:
#    docker exec -it postgres psql -U postgres -c "CREATE USER wikijs WITH PASSWORD 'password_here';"
#    docker exec -it postgres psql -U postgres -c "CREATE USER homeassistant WITH PASSWORD 'password_here';"
#    docker exec -it postgres psql -U postgres -c "CREATE USER immich WITH PASSWORD 'password_here';"
# 4. Grant permissions:
#    docker exec -it postgres psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE wikijs TO wikijs;"
#    docker exec -it postgres psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE homeassistant TO homeassistant;"
#    docker exec -it postgres psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE immich TO immich;"
#
# Last Updated: November 6, 2025
# =========================================

version: '3.9'

services:
  postgres:
    image: postgres:16.1-alpine
    container_name: postgres
    hostname: postgres-server

    restart: unless-stopped

    # Resource limits tuned for 3 concurrent databases
    # PostgreSQL memory usage formula:
    # shared_buffers (4GB) + work_mem * max_connections (16MB * 100) + maintenance_work_mem (512MB)
    # Estimated peak: 6GB RAM, 2 CPU cores
    # Observed typical: 3GB RAM, 0.5 CPU cores
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 12G
        reservations:
          cpus: '1.0'
          memory: 4G

    environment:
      # Superuser password (for administrative tasks only)
      # Never use this password for application connections
      # Rotate quarterly and store in password manager
      POSTGRES_PASSWORD: ${POSTGRES_SUPERUSER_PASSWORD}

      # Default database created on first start
      # We'll create service-specific databases manually
      POSTGRES_DB: postgres

      # Timezone for timestamp columns
      TZ: America/Los_Angeles

      # PostgreSQL configuration tuning
      # These values are optimized for 16GB RAM, 4 CPU homelab VM
      # Based on pgtune.leopard.in.ua recommendations

      # Memory Configuration
      # --------------------
      # shared_buffers: Amount of memory for caching data
      # Recommendation: 25% of total RAM
      # 16GB * 0.25 = 4GB
      POSTGRES_SHARED_BUFFERS: 4GB

      # effective_cache_size: Estimate of OS cache available
      # Recommendation: 50-75% of total RAM
      # Used by query planner to estimate disk cache hits
      POSTGRES_EFFECTIVE_CACHE_SIZE: 12GB

      # work_mem: Memory for sorting and hash operations
      # Recommendation: (Total RAM / max_connections) / 4
      # (16GB / 100) / 4 = 40MB
      POSTGRES_WORK_MEM: 40MB

      # maintenance_work_mem: Memory for VACUUM, CREATE INDEX
      # Recommendation: 5-10% of RAM
      POSTGRES_MAINTENANCE_WORK_MEM: 1GB

      # Connection Configuration
      # ------------------------
      # max_connections: Maximum concurrent connections
      # Includes application connections + admin connections
      # Wiki.js: 10, Home Assistant: 20, Immich: 15, Admin: 5
      # Total: 50 connections, set max to 100 for headroom
      POSTGRES_MAX_CONNECTIONS: 100

      # Performance Tuning
      # ------------------
      # random_page_cost: Cost of random disk I/O
      # SSD: 1.1, HDD: 4.0
      # VM is on SSD, set to 1.1
      POSTGRES_RANDOM_PAGE_COST: 1.1

      # effective_io_concurrency: Concurrent I/O operations
      # SSD: 200, HDD: 2
      POSTGRES_EFFECTIVE_IO_CONCURRENCY: 200

      # Write-Ahead Log (WAL) Configuration
      # ------------------------------------
      # wal_buffers: Memory for WAL before flushing to disk
      # Recommendation: 16MB (or -1 for auto-tuning)
      POSTGRES_WAL_BUFFERS: 16MB

      # checkpoint_completion_target: Spread checkpoint I/O over time
      # Range: 0.0-1.0, recommended: 0.9
      # Higher values = smoother I/O, less performance spikes
      POSTGRES_CHECKPOINT_COMPLETION_TARGET: 0.9

      # Logging Configuration
      # ---------------------
      # Log slow queries for performance analysis
      # Queries taking >1 second will be logged
      POSTGRES_LOG_MIN_DURATION_STATEMENT: 1000

      # Log all DDL statements (CREATE, ALTER, DROP)
      POSTGRES_LOG_STATEMENT: ddl

      # Autovacuum Configuration
      # ------------------------
      # Autovacuum prevents table bloat and maintains statistics
      # These settings are aggressive for frequently updated tables
      POSTGRES_AUTOVACUUM_MAX_WORKERS: 3
      POSTGRES_AUTOVACUUM_NAPTIME: 1min

    ports:
      # PostgreSQL standard port
      # Listen on all interfaces, firewall controls access
      - "5432:5432"

    volumes:
      # Data directory (contains all databases, WAL files, configs)
      # CRITICAL: This must be persistent and backed up regularly
      # Size: Starts at 200MB, grows to ~10GB with all services
      - /opt/postgresql/data:/var/lib/postgresql/data

      # Backup directory (for pg_dump outputs)
      # Automated backup script will write here
      - /opt/postgresql/backups:/backups

      # Initialization scripts (run once on first start)
      # Place .sql or .sh files here to auto-create databases/users
      # - ./init-scripts:/docker-entrypoint-initdb.d:ro

      # Custom postgresql.conf (optional - env vars above cover most tuning)
      # - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro

      # Timezone data
      - /etc/localtime:/etc/localtime:ro

    # Health check verifies database is accepting connections
    # Used by Prometheus and Docker to detect service degradation
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

    networks:
      - postgres_network

    labels:
      # Prometheus scraping (requires postgres_exporter sidecar)
      - "prometheus.io/scrape=false"  # Enable after adding exporter
      - "com.example.service=postgresql"
      - "com.example.description=Centralized PostgreSQL database server"
      - "com.example.team=homelab"
      - "backup.enable=true"
      - "backup.schedule=daily"
      - "backup.retention=30d"

    # Logging configuration
    # PostgreSQL can be verbose with query logging
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"
        labels: "service"

    # Security options
    security_opt:
      - no-new-privileges:true

# =================================================
# Networks
# =================================================
networks:
  postgres_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.23.0.0/16
    labels:
      - "com.example.description=PostgreSQL network"

# =========================================
# OPERATIONAL NOTES
# =========================================
#
# Backup Strategy:
# ----------------
# Automated backup script (save as /opt/postgresql/backup.sh)
#
# #!/bin/bash
# BACKUP_DIR="/opt/postgresql/backups"
# TIMESTAMP=$(date +%Y%m%d_%H%M%S)
# docker exec postgres pg_dumpall -U postgres | gzip > "$BACKUP_DIR/all-databases-$TIMESTAMP.sql.gz"
# find "$BACKUP_DIR" -name "*.sql.gz" -mtime +30 -delete
#
# =========================================
