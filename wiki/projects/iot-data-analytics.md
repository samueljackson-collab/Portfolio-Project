---
title: "IoT Data Analytics"
description: "Edge-to-cloud ingestion stack with MQTT telemetry and anomaly detection."
published: true
date: 2026-01-23T15:24:46.000Z
tags:
  - iot
  - analytics
  - timescaledb
  - mqtt
  - machine-learning
editor: markdown
dateCreated: 2026-01-23T15:24:46.000Z
---


# IoT Data Analytics

> **Status**: Production Ready | **Completion**: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
>
> `iot` `analytics` `timescaledb` `mqtt` `machine-learning`

Edge-to-cloud ingestion stack with MQTT telemetry and anomaly detection.

---


## üìã Table of Contents

1. [Problem Statement](#-problem-statement) - Why this project exists
2. [Learning Objectives](#-learning-objectives) - What you'll learn
3. [Architecture](#-architecture) - System design and components
4. [Tech Stack](#-tech-stack) - Technologies and their purposes
5. [Technology Deep Dives](#-technology-deep-dives) - In-depth explanations
6. [Implementation Guide](#-implementation-guide) - How to build it
7. [Best Practices](#-best-practices) - Do's and don'ts
8. [Quick Start](#-quick-start) - Get running in minutes
9. [Operational Guide](#-operational-guide) - Day-2 operations
10. [Real-World Scenarios](#-real-world-scenarios) - Practical applications

---


## üéØ Problem Statement

### The Physical-Digital Bridge Challenge

Connecting physical devices to digital systems at scale presents unique challenges:

**The Scale Problem**: Traditional architectures collapse under millions of concurrent
device connections. Each device needs authentication, message routing, and state
management.

**The Connectivity Problem**: Devices operate in hostile network conditions‚Äîintermittent
cellular, bandwidth constraints, high latency. Systems must handle disconnection
gracefully.

**The Data Velocity Problem**: Sensors generate continuous streams of telemetry.
Storing raw data is expensive. Processing it in real-time requires specialized
infrastructure.

**The Edge Problem**: Sending all data to the cloud adds latency and cost. Some
processing must happen at the edge, close to devices.


**Business Impact:**
- Missed insights from data that can't be processed
- High cloud costs from inefficient data handling
- Poor user experience from latency
- Security vulnerabilities from unmanaged devices
- Operational blind spots from monitoring gaps


### How This Project Solves It


**Modern IoT architecture addresses these challenges:**

1. **Managed Connectivity**: Cloud IoT services handle millions of device connections
   with authentication, routing, and device shadows.

2. **Edge Computing**: Process data locally for low-latency responses. Send only
   relevant data to the cloud.

3. **Time-Series Storage**: Specialized databases optimized for high-frequency
   telemetry ingestion and time-based queries.

4. **ML at the Edge**: Run anomaly detection and inference models on devices for
   real-time insights without cloud round-trips.


### Key Capabilities Delivered

- ‚úÖ **Device provisioning automation**
- ‚úÖ **ML-based anomaly detection**
- ‚úÖ **Real-time telemetry**
- ‚úÖ **Infrastructure as Code**

---


## üéì Learning Objectives

By studying and implementing this project, you will:

   1. Design edge-to-cloud data pipelines
   2. Implement secure device provisioning and authentication
   3. Build real-time telemetry processing and storage
   4. Configure anomaly detection for sensor data
   5. Implement device management and OTA updates

**Prerequisites:**
- Basic understanding of cloud services (AWS/GCP/Azure)
- Familiarity with containerization (Docker)
- Command-line proficiency (Bash/Linux)
- Version control with Git

**Estimated Learning Time:** 15-25 hours for full implementation

---


## üèóÔ∏è Architecture

### High-Level System Design

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         IoT Data Analytics                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ   ‚îÇ    INPUT      ‚îÇ    ‚îÇ   PROCESSING    ‚îÇ    ‚îÇ     OUTPUT        ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ               ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ ‚Ä¢ API Gateway ‚îÇ    ‚îÇ ‚Ä¢ Business Logic‚îÇ    ‚îÇ ‚Ä¢ Response/Events ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ ‚Ä¢ Event Queue ‚îÇ    ‚îÇ ‚Ä¢ Validation    ‚îÇ    ‚îÇ ‚Ä¢ Persistence     ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ ‚Ä¢ File Upload ‚îÇ    ‚îÇ ‚Ä¢ Transformation‚îÇ    ‚îÇ ‚Ä¢ Notifications   ‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                       ‚îÇ              ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                                ‚îÇ                                       ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                    ‚îÇ    INFRASTRUCTURE     ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Compute (EKS/Lambda)‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Storage (S3/RDS)    ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Network (VPC/ALB)   ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Security (IAM/KMS)  ‚îÇ                          ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Design Decisions

| Decision | Rationale |
|----------|-----------|
| Multi-AZ Deployment | Ensures high availability during AZ failures |
| Managed Services | Reduces operational burden, focus on business logic |
| Infrastructure as Code | Reproducibility, version control, audit trail |
| GitOps Workflow | Single source of truth, automated reconciliation |

---


## üõ†Ô∏è Tech Stack

### Technologies Used

| Technology | Purpose & Rationale |
|------------|---------------------|
| **AWS IoT Core** | Managed MQTT broker handling billions of messages from IoT devices |
| **Python** | Primary automation language for scripts, data processing, and ML pipelines |
| **TimescaleDB** | PostgreSQL extension optimized for time-series data at scale |
| **MQTT** | Lightweight pub/sub protocol designed for constrained IoT devices |
| **Scikit-learn** | Production-ready ML algorithms with consistent API |

### Why This Combination?

This stack was carefully selected based on:

1. **Production Maturity** - All components are battle-tested at scale
2. **Community & Ecosystem** - Strong documentation, plugins, and support
3. **Integration** - Technologies work together with established patterns
4. **Scalability** - Architecture supports growth without major refactoring
5. **Operability** - Built-in observability and debugging capabilities
6. **Cost Efficiency** - Balance of capability and cloud spend optimization

### Alternative Considerations

| Current Choice | Alternatives Considered | Why Current Was Chosen |
|---------------|------------------------|------------------------|
| Terraform | CloudFormation, Pulumi | Provider-agnostic, mature ecosystem |
| Kubernetes | ECS, Nomad | Industry standard, portable |
| PostgreSQL | MySQL, MongoDB | ACID compliance, JSON support |

---

## üî¨ Technology Deep Dives

### üìö Why IoT Architecture?

Internet of Things (IoT) architecture connects physical devices to cloud
services for data collection, analysis, and actuation. Modern IoT systems span
edge computing, communication protocols, time-series databases, and real-time
analytics‚Äîhandling millions of devices generating continuous telemetry.

IoT enables digital twins, predictive maintenance, smart automation, and
data-driven insights from the physical world.

#### How It Works


**IoT Architecture Layers:**
1. **Device Layer**: Sensors, actuators, microcontrollers
2. **Edge Layer**: Local processing, protocol translation
3. **Network Layer**: MQTT, CoAP, cellular, LoRaWAN
4. **Platform Layer**: Device management, message routing
5. **Application Layer**: Analytics, dashboards, ML models

**Data Flow:**
- Devices ‚Üí Edge Gateway ‚Üí Cloud Broker ‚Üí Storage ‚Üí Analytics
- Commands flow in reverse for actuation


#### Working Code Example

```python
# Example: IoT Device Simulator with MQTT
import paho.mqtt.client as mqtt
import json
import time
import random
from datetime import datetime

class IoTDevice:
    """Simulated IoT sensor device."""

    def __init__(self, device_id: str, broker: str, port: int = 8883):
        self.device_id = device_id
        self.client = mqtt.Client(client_id=device_id, protocol=mqtt.MQTTv5)

        # TLS configuration for secure connection
        self.client.tls_set(
            ca_certs='certs/root-ca.pem',
            certfile=f'certs/{device_id}.cert.pem',
            keyfile=f'certs/{device_id}.private.key'
        )

        # Callbacks
        self.client.on_connect = self._on_connect
        self.client.on_message = self._on_message
        self.client.on_disconnect = self._on_disconnect

        # Connect to broker
        self.client.connect(broker, port, keepalive=60)
        self.client.loop_start()

    def _on_connect(self, client, userdata, flags, rc, properties=None):
        print(f"Device {self.device_id} connected with code {rc}")
        # Subscribe to command topic
        client.subscribe(f"devices/{self.device_id}/commands")

    def _on_message(self, client, userdata, msg):
        print(f"Received command: {msg.payload.decode()}")
        command = json.loads(msg.payload.decode())
        self._handle_command(command)

    def _on_disconnect(self, client, userdata, rc):
        print(f"Device {self.device_id} disconnected")

    def _handle_command(self, command: dict):
        """Process commands from cloud."""
        if command.get('action') == 'reboot':
            print("Rebooting device...")
        elif command.get('action') == 'update_config':
            print(f"Updating config: {command.get('config')}")

    def publish_telemetry(self):
        """Publish sensor readings."""
        telemetry = {
            'device_id': self.device_id,
            'timestamp': datetime.utcnow().isoformat(),
            'sensors': {
                'temperature': round(random.uniform(20, 30), 2),
                'humidity': round(random.uniform(40, 60), 2),
                'pressure': round(random.uniform(1000, 1020), 2),
                'battery': round(random.uniform(80, 100), 1)
            },
            'metadata': {
                'firmware_version': '1.2.3',
                'signal_strength': random.randint(-80, -40)
            }
        }

        topic = f"devices/{self.device_id}/telemetry"
        self.client.publish(
            topic,
            json.dumps(telemetry),
            qos=1  # At least once delivery
        )
        print(f"Published: {telemetry['sensors']}")

    def run(self, interval: int = 5):
        """Main loop publishing telemetry at interval."""
        try:
            while True:
                self.publish_telemetry()
                time.sleep(interval)
        except KeyboardInterrupt:
            self.client.loop_stop()
            self.client.disconnect()

if __name__ == '__main__':
    device = IoTDevice(
        device_id='sensor-001',
        broker='iot.example.com'
    )
    device.run(interval=10)
```

#### Key Benefits

- **Real-Time Data**: Continuous telemetry streams from physical world
- **Edge Processing**: Reduce latency with local compute
- **Scalability**: Handle millions of devices with managed services
- **Predictive Insights**: ML-powered anomaly detection and forecasting
- **Automation**: Trigger actions based on sensor data
- **Digital Twins**: Virtual representations of physical assets
- **Cost Optimization**: Predictive maintenance reduces downtime

#### Best Practices

- ‚úÖ Use TLS/mTLS for all device communication
- ‚úÖ Implement device provisioning with unique credentials
- ‚úÖ Design for intermittent connectivity (store-and-forward)
- ‚úÖ Use time-series databases optimized for telemetry
- ‚úÖ Implement firmware OTA updates with rollback
- ‚úÖ Set up alerting on device health metrics

#### Common Pitfalls to Avoid

- ‚ùå Hardcoded credentials in device firmware
- ‚ùå Unencrypted communication channels
- ‚ùå Sending raw data without edge preprocessing
- ‚ùå Ignoring device lifecycle management
- ‚ùå Using relational databases for high-frequency telemetry

#### Further Reading

- [AWS IoT Documentation](https://docs.aws.amazon.com/iot/)
- [MQTT Protocol](https://mqtt.org/getting-started/)
- [TimescaleDB for IoT](https://docs.timescale.com/use-cases/latest/industrial-iot/)

---



## üìñ Implementation Guide

This section provides production-ready code you can adapt for your own projects.

### Step 1: Implementing Device provisioning automation

**Objective:** Build device provisioning automation with production-grade quality.

**Implementation Approach:**

1. **Define Requirements**
   - Functional: What it must do
   - Non-functional: Performance, security, reliability targets

2. **Design the Solution**
   - Consider failure modes and edge cases
   - Plan for observability from the start
   - Document architectural decisions

3. **Implement Iteratively**
   - Start with a minimal working version
   - Add tests before extending functionality
   - Refactor for clarity and maintainability

4. **Validate Thoroughly**
   - Unit tests for business logic
   - Integration tests for component interaction
   - Load tests for performance validation

### Step 2: Implementing ML-based anomaly detection

**Objective:** Build ml-based anomaly detection with production-grade quality.

**Implementation Approach:**

1. **Define Requirements**
   - Functional: What it must do
   - Non-functional: Performance, security, reliability targets

2. **Design the Solution**
   - Consider failure modes and edge cases
   - Plan for observability from the start
   - Document architectural decisions

3. **Implement Iteratively**
   - Start with a minimal working version
   - Add tests before extending functionality
   - Refactor for clarity and maintainability

4. **Validate Thoroughly**
   - Unit tests for business logic
   - Integration tests for component interaction
   - Load tests for performance validation

### Step 3: Implementing Real-time telemetry

**Objective:** Build real-time telemetry with production-grade quality.

**Implementation Approach:**

1. **Define Requirements**
   - Functional: What it must do
   - Non-functional: Performance, security, reliability targets

2. **Design the Solution**
   - Consider failure modes and edge cases
   - Plan for observability from the start
   - Document architectural decisions

3. **Implement Iteratively**
   - Start with a minimal working version
   - Add tests before extending functionality
   - Refactor for clarity and maintainability

4. **Validate Thoroughly**
   - Unit tests for business logic
   - Integration tests for component interaction
   - Load tests for performance validation

---


## ‚úÖ Best Practices

### Infrastructure

| Practice | Description | Why It Matters |
|----------|-------------|----------------|
| **Infrastructure as Code** | Define all resources in version-controlled code | Reproducibility, audit trail, peer review |
| **Immutable Infrastructure** | Replace instances, don't modify them | Consistency, easier rollback, no drift |
| **Least Privilege** | Grant minimum required permissions | Security, blast radius reduction |
| **Multi-AZ Deployment** | Distribute across availability zones | High availability during AZ failures |

### Security

- ‚õî **Never** hardcode credentials in source code
- ‚õî **Never** commit secrets to version control
- ‚úÖ **Always** use IAM roles over access keys
- ‚úÖ **Always** encrypt data at rest and in transit
- ‚úÖ **Always** enable audit logging (CloudTrail, VPC Flow Logs)

### Operations

1. **Observability First**
   - Instrument code before production deployment
   - Establish baselines for normal behavior
   - Create actionable alerts, not noise

2. **Automate Everything**
   - Manual processes don't scale
   - Runbooks should be scripts, not documents
   - Test automation regularly

3. **Practice Failure**
   - Regular DR drills validate recovery procedures
   - Chaos engineering builds confidence
   - Document and learn from incidents

### Code Quality

```python
# ‚úÖ Good: Clear, testable, observable
class PaymentProcessor:
    def __init__(self, gateway: PaymentGateway, metrics: MetricsClient):
        self.gateway = gateway
        self.metrics = metrics
        self.logger = logging.getLogger(__name__)

    def process(self, payment: Payment) -> Result:
        self.logger.info(f"Processing payment {payment.id}")
        start = time.time()

        try:
            result = self.gateway.charge(payment)
            self.metrics.increment("payments.success")
            return result
        except GatewayError as e:
            self.metrics.increment("payments.failure")
            self.logger.error(f"Payment failed: {e}")
            raise
        finally:
            self.metrics.timing("payments.duration", time.time() - start)

# ‚ùå Bad: Untestable, no observability
def process_payment(payment):
    return requests.post(GATEWAY_URL, json=payment).json()
```

---


## üöÄ Quick Start

### Prerequisites

Before you begin, ensure you have:

- [ ] **Docker** (20.10+) and Docker Compose installed
- [ ] **Python** 3.11+ with pip
- [ ] **AWS CLI** configured with appropriate credentials
- [ ] **kubectl** installed and configured
- [ ] **Terraform** 1.5+ installed
- [ ] **Git** for version control

### Step 1: Clone the Repository

```bash
git clone https://github.com/samueljackson-collab/Portfolio-Project.git
cd Portfolio-Project/projects/11-iot-data-analytics
```

### Step 2: Review the Documentation

```bash
# Read the project README
cat README.md

# Review available make targets
make help
```

### Step 3: Set Up Environment

```bash
# Copy environment template
cp .env.example .env

# Edit with your configuration
vim .env

# Validate configuration
make validate-config
```

### Step 4: Start Local Development

```bash
# Start all services with Docker Compose
make up

# Verify services are running
make status

# View logs
make logs

# Run tests
make test
```

### Step 5: Deploy to Cloud

```bash
# Initialize Terraform
cd terraform
terraform init

# Review planned changes
terraform plan -out=tfplan

# Apply infrastructure
terraform apply tfplan

# Deploy application
cd ..
make deploy ENV=staging
```

### Verification

```bash
# Check deployment health
make health

# Run smoke tests
make smoke-test

# View dashboards
open http://localhost:3000  # Grafana
```

---


## ‚öôÔ∏è Operational Guide

### Monitoring & Alerting

| Metric Type | Tool | Dashboard |
|-------------|------|-----------|
| **Metrics** | Prometheus | Grafana `http://localhost:3000` |
| **Logs** | Loki | Grafana Explore |
| **Traces** | Tempo/Jaeger | Grafana Explore |
| **Errors** | Sentry | `https://sentry.io/org/project` |

### Key Metrics to Monitor

```promql
# Request latency (P99)
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

# Error rate
sum(rate(http_requests_total{status=~"5.."}[5m])) /
sum(rate(http_requests_total[5m]))

# Resource utilization
container_memory_usage_bytes / container_spec_memory_limit_bytes
```

### Common Operations

| Task | Command | When to Use |
|------|---------|-------------|
| View logs | `kubectl logs -f deploy/app` | Debugging issues |
| Scale up | `kubectl scale deploy/app --replicas=5` | Handling load |
| Rollback | `kubectl rollout undo deploy/app` | Bad deployment |
| Port forward | `kubectl port-forward svc/app 8080:80` | Local debugging |
| Exec into pod | `kubectl exec -it deploy/app -- bash` | Investigation |

### Runbooks

<details>
<summary><strong>üî¥ High Error Rate</strong></summary>

**Symptoms:** Error rate exceeds 1% threshold

**Investigation:**
1. Check recent deployments: `kubectl rollout history deploy/app`
2. Review error logs: `kubectl logs -l app=app --since=1h | grep ERROR`
3. Check dependency health: `make check-dependencies`
4. Review metrics dashboard for patterns

**Resolution:**
- If recent deployment: `kubectl rollout undo deploy/app`
- If dependency failure: Check upstream service status
- If resource exhaustion: Scale horizontally or vertically

**Escalation:** Page on-call if not resolved in 15 minutes
</details>

<details>
<summary><strong>üü° High Latency</strong></summary>

**Symptoms:** P99 latency > 500ms

**Investigation:**
1. Check traces for slow operations
2. Review database query performance
3. Check for resource constraints
4. Review recent configuration changes

**Resolution:**
- Identify slow queries and optimize
- Add caching for frequently accessed data
- Scale database read replicas
- Review and optimize N+1 queries
</details>

<details>
<summary><strong>üîµ Deployment Failure</strong></summary>

**Symptoms:** ArgoCD sync fails or pods not ready

**Investigation:**
1. Check ArgoCD UI for sync errors
2. Review pod events: `kubectl describe pod <pod>`
3. Check image pull status
4. Verify secrets and config maps exist

**Resolution:**
- Fix manifest issues and re-sync
- Ensure image exists in registry
- Verify RBAC permissions
- Check resource quotas
</details>

### Disaster Recovery

**RTO Target:** 15 minutes
**RPO Target:** 1 hour

```bash
# Failover to DR region
./scripts/dr-failover.sh --region us-west-2

# Validate data integrity
./scripts/dr-validate.sh

# Failback to primary
./scripts/dr-failback.sh --region us-east-1
```

---


## üåç Real-World Scenarios

These scenarios demonstrate how this project applies to actual business situations.

### Scenario: Production Traffic Surge

**Challenge:** Application needs to handle 5x normal traffic during peak events.

**Solution:** Auto-scaling policies trigger based on CPU and request metrics.
Load testing validates capacity before the event. Runbooks document
manual intervention procedures if automated scaling is insufficient.

---

### Scenario: Security Incident Response

**Challenge:** Vulnerability discovered in production dependency.

**Solution:** Automated scanning detected the CVE. Patch branch created
and tested within hours. Rolling deployment updated all instances with
zero downtime. Audit trail documented the entire response timeline.

---


## üîó Related Projects

Explore these related projects that share technologies or concepts:

| Project | Description | Shared Tags |
|---------|-------------|-------------|
| [MLOps Platform](/projects/mlops-platform) | End-to-end MLOps workflow for training, evaluating... | 1 |
| [Edge AI Inference Platform](/projects/edge-ai-inference-platform) | Containerized ONNX Runtime microservice for edge d... | 1 |

---


## üìö Resources

### Project Links

| Resource | Link |
|----------|------|
| üìÇ Source Code | [GitHub Repository](https://github.com/samueljackson-collab/Portfolio-Project/tree/main/projects/11-iot-data-analytics) |
| üìñ Documentation | [`projects/11-iot-data-analytics/docs/`](projects/11-iot-data-analytics/docs/) |
| üêõ Issues | [Report bugs or request features](https://github.com/samueljackson-collab/Portfolio-Project/issues) |

### Recommended Reading

- [The Twelve-Factor App](https://12factor.net/)
- [Google SRE Book](https://sre.google/sre-book/table-of-contents/)
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)

### Community Resources

- Stack Overflow: Tag your questions appropriately
- Reddit: r/devops, r/aws, r/kubernetes
- Discord: Many technology-specific servers

---

<div align="center">

**Last Updated:** 2026-01-23 |
**Version:** 3.0 |
**Generated by:** Portfolio Wiki Content Generator

*Found this helpful? Star the repository!*

</div>
