{
  "metadata": {
    "name": "Portfolio Merge and Organization System",
    "version": "1.0.0",
    "created": "2025-11-10",
    "branch": "claude/day-1-portfolio-foundation-011CUzXj1ueqmozvq5Z3k3mP",
    "repository": "https://github.com/samueljackson-collab/Portfolio-Project",
    "description": "Automated tools for extracting, analyzing, merging, and organizing portfolio projects",
    "author": "Claude AI",
    "purpose": "Consolidate multiple portfolio versions, eliminate duplicates, standardize structure"
  },

  "repository_analysis": {
    "current_state": {
      "total_projects": 68,
      "markdown_files": 148,
      "readme_files": 70,
      "changelog_files": 20,
      "python_files": 70,
      "terraform_files": 32,
      "yaml_files": 51,
      "shell_scripts": 23,
      "estimated_duplicate_groups": 15,
      "naming_conventions": 3
    },
    "naming_patterns": {
      "category_based": {
        "pattern": "XX-category-name/PRJ-CODE-###",
        "count": 15,
        "examples": [
          "01-sde-devops/PRJ-SDE-001",
          "02-cloud-architecture/PRJ-CLOUD-001",
          "03-cybersecurity/PRJ-CYB-BLUE-001"
        ]
      },
      "p_numbered": {
        "pattern": "p##-project-name",
        "count": 20,
        "examples": [
          "p01-aws-infra",
          "p02-iam-hardening",
          "p03-hybrid-network"
        ]
      },
      "simple_numbered": {
        "pattern": "#-project-name",
        "count": 33,
        "examples": [
          "1-aws-infrastructure-automation",
          "2-database-migration",
          "3-kubernetes-cicd"
        ]
      }
    },
    "issues_identified": [
      "Multiple naming conventions causing confusion",
      "Potential duplicates across naming schemes",
      "Inconsistent structure between projects",
      "Some incomplete projects with placeholders",
      "Missing standardization in documentation"
    ],
    "recommended_structure": {
      "naming_convention": "Category-based with project codes",
      "format": "XX-category/PRJ-CODE-###-name",
      "expected_final_count": 50,
      "categories": [
        "01-sde-devops",
        "02-cloud-architecture",
        "03-cybersecurity",
        "04-qa-testing",
        "05-networking-datacenter",
        "06-homelab",
        "07-data-engineering",
        "08-aiml",
        "09-web-applications",
        "10-advanced-topics"
      ]
    }
  },

  "archive_files_needed": [
    "fixed_bundle_20251021_135306.zip",
    "Homelab project.zip",
    "Portfolio v2.zip",
    "portfolio_docs_v3_bundle.zip",
    "homelab_diagrams_and_photos.tar.gz",
    "homelab_diagrams_v9_1.tar.gz",
    "portfolio_repo_unified_20251001-170421.tar.gz",
    "RedTeam_Bundle.tar.gz",
    "Deep_Research_Plan_Execution - Copy.zip",
    "Portfolio.zip",
    "portfolio_final_bundle.zip",
    "files (1).zip",
    "files (2).zip",
    "files (3).zip",
    "files (4).zip",
    "Twisted_Monk_Suite_v1_export.zip",
    "twisted_monk_suite_repo.zip"
  ],

  "tools": {
    "extract_all_archives": {
      "name": "extract-all-archives.sh",
      "language": "bash",
      "purpose": "Extract all archive files with manifest generation",
      "runtime": "2-5 minutes",
      "inputs": ["*.zip", "*.tar.gz", "*.tar files in repo root or archives/"],
      "outputs": ["temp_extraction/", "temp_extraction/extraction_manifest.txt"],
      "features": [
        "Auto-detects archive types",
        "Organized extraction to temp directory",
        "Comprehensive manifest generation",
        "File and directory counting",
        "README and project directory identification"
      ],
      "usage": "./scripts/extract-all-archives.sh",
      "script": "#!/bin/bash\n# Extract All Portfolio Archives\n# Purpose: Extract all archive files to organized temp directory structure\n\nset -e  # Exit on error\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nREPO_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\nEXTRACT_BASE=\"$REPO_ROOT/temp_extraction\"\nMANIFEST_FILE=\"$EXTRACT_BASE/extraction_manifest.txt\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\necho -e \"${BLUE}=== Portfolio Archive Extraction Tool ===${NC}\"\necho \"Repository: $REPO_ROOT\"\necho \"Extract to: $EXTRACT_BASE\"\necho \"\"\n\n# Create extraction base directory\nmkdir -p \"$EXTRACT_BASE\"\n\n# Initialize manifest\necho \"# Archive Extraction Manifest\" > \"$MANIFEST_FILE\"\necho \"# Generated: $(date)\" >> \"$MANIFEST_FILE\"\necho \"\" >> \"$MANIFEST_FILE\"\n\n# Function to extract an archive\nextract_archive() {\n    local archive_path=\"$1\"\n    local archive_name=$(basename \"$archive_path\")\n    local extract_dir=\"$EXTRACT_BASE/${archive_name%.*}\"\n\n    echo -e \"${YELLOW}Processing: $archive_name${NC}\"\n\n    # Create extraction directory\n    mkdir -p \"$extract_dir\"\n\n    # Detect archive type and extract\n    case \"$archive_path\" in\n        *.tar.gz|*.tgz)\n            echo \"  Extracting tar.gz archive...\"\n            tar -xzf \"$archive_path\" -C \"$extract_dir\" 2>&1 | head -10\n            ;;\n        *.tar)\n            echo \"  Extracting tar archive...\"\n            tar -xf \"$archive_path\" -C \"$extract_dir\" 2>&1 | head -10\n            ;;\n        *.zip)\n            echo \"  Extracting zip archive...\"\n            unzip -q \"$archive_path\" -d \"$extract_dir\" 2>&1 | head -10\n            ;;\n        *)\n            echo -e \"  ${RED}Unknown archive type, skipping${NC}\"\n            return 1\n            ;;\n    esac\n\n    # Count contents\n    local file_count=$(find \"$extract_dir\" -type f | wc -l)\n    local dir_count=$(find \"$extract_dir\" -type d | wc -l)\n\n    echo -e \"  ${GREEN}✓ Extracted: $file_count files, $dir_count directories${NC}\"\n\n    # Add to manifest\n    echo \"## $archive_name\" >> \"$MANIFEST_FILE\"\n    echo \"Location: $extract_dir\" >> \"$MANIFEST_FILE\"\n    echo \"Files: $file_count\" >> \"$MANIFEST_FILE\"\n    echo \"Directories: $dir_count\" >> \"$MANIFEST_FILE\"\n    echo \"Extracted: $(date)\" >> \"$MANIFEST_FILE\"\n    echo \"\" >> \"$MANIFEST_FILE\"\n\n    # List top-level contents\n    echo \"### Top-level contents:\" >> \"$MANIFEST_FILE\"\n    ls -la \"$extract_dir\" 2>/dev/null | head -20 >> \"$MANIFEST_FILE\"\n    echo \"\" >> \"$MANIFEST_FILE\"\n\n    # Find README files\n    echo \"### README files found:\" >> \"$MANIFEST_FILE\"\n    find \"$extract_dir\" -name \"README.md\" -type f >> \"$MANIFEST_FILE\"\n    echo \"\" >> \"$MANIFEST_FILE\"\n\n    # Find project directories\n    echo \"### Project directories:\" >> \"$MANIFEST_FILE\"\n    find \"$extract_dir\" -type d -name \"p[0-9]*\" -o -name \"PRJ-*\" -o -name \"[0-9]*-*\" 2>/dev/null | sort >> \"$MANIFEST_FILE\"\n    echo \"\" >> \"$MANIFEST_FILE\"\n    echo \"---\" >> \"$MANIFEST_FILE\"\n    echo \"\" >> \"$MANIFEST_FILE\"\n\n    return 0\n}\n\n# Find all archives\necho -e \"${BLUE}Searching for archive files...${NC}\"\narchives_found=0\n\n# Search in common locations\nsearch_locations=(\n    \"$REPO_ROOT\"\n    \"$REPO_ROOT/downloads\"\n    \"$REPO_ROOT/archives\"\n    \"$(pwd)\"\n)\n\nfor location in \"${search_locations[@]}\"; do\n    if [ -d \"$location\" ]; then\n        echo \"Searching: $location\"\n        while IFS= read -r -d '' archive; do\n            extract_archive \"$archive\"\n            ((archives_found++))\n        done < <(find \"$location\" -maxdepth 1 \\( -name \"*.zip\" -o -name \"*.tar.gz\" -o -name \"*.tar\" -o -name \"*.tgz\" \\) -type f -print0 2>/dev/null)\n    fi\ndone\n\necho \"\"\necho -e \"${BLUE}=== Extraction Complete ===${NC}\"\necho -e \"Archives processed: ${GREEN}$archives_found${NC}\"\necho -e \"Manifest file: ${GREEN}$MANIFEST_FILE${NC}\"\necho -e \"Extraction directory: ${GREEN}$EXTRACT_BASE${NC}\"\n\nif [ $archives_found -eq 0 ]; then\n    echo \"\"\n    echo -e \"${RED}⚠ No archive files found!${NC}\"\n    echo \"\"\n    echo \"Expected archive files:\"\n    echo \"  - fixed_bundle_20251021_135306.zip\"\n    echo \"  - Homelab project.zip\"\n    echo \"  - Portfolio v2.zip\"\n    echo \"  - portfolio_docs_v3_bundle.zip\"\n    echo \"  - homelab_diagrams_and_photos.tar.gz\"\n    echo \"  - And others...\"\n    echo \"\"\n    echo \"Please place archive files in one of these locations:\"\n    for loc in \"${search_locations[@]}\"; do\n        echo \"  - $loc\"\n    done\n    exit 1\nfi\n\necho \"\"\necho -e \"${GREEN}Next steps:${NC}\"\necho \"1. Review manifest: cat $MANIFEST_FILE\"\necho \"2. Run duplicate detection: ./scripts/detect-duplicates.sh\"\necho \"3. Compare versions: ./scripts/compare-versions.py\"\n\nexit 0"
    },

    "detect_duplicates": {
      "name": "detect-duplicates.sh",
      "language": "bash",
      "purpose": "Identify duplicate projects across naming conventions and versions",
      "runtime": "1-2 minutes",
      "inputs": ["projects/ directory", "temp_extraction/ directory"],
      "outputs": ["docs/DUPLICATE_DETECTION_REPORT.md"],
      "features": [
        "Fuzzy name matching across naming conventions",
        "Scans current repo and extracted archives",
        "Groups potential duplicates",
        "README and file count comparison",
        "Detailed report generation"
      ],
      "usage": "./scripts/detect-duplicates.sh",
      "algorithm": {
        "step1": "Normalize project names (remove prefixes, lowercase)",
        "step2": "Group projects by normalized names",
        "step3": "Extract keywords from README files",
        "step4": "Compare file structures and counts",
        "step5": "Generate grouped duplicate report"
      },
      "script": "#!/bin/bash\n# Detect Duplicate Projects\n# Purpose: Find duplicate projects across different naming conventions and archive versions\n\nset -e\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nREPO_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\nEXTRACT_BASE=\"$REPO_ROOT/temp_extraction\"\nCURRENT_PROJECTS=\"$REPO_ROOT/projects\"\nREPORT_FILE=\"$REPO_ROOT/docs/DUPLICATE_DETECTION_REPORT.md\"\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m'\n\necho -e \"${BLUE}=== Duplicate Project Detection ===${NC}\"\necho \"\"\n\n# Initialize report\ncat > \"$REPORT_FILE\" << 'EOF'\n# Duplicate Project Detection Report\n\n**Generated:** $(date)\n**Purpose:** Identify duplicate projects across naming conventions and archive versions\n\n---\n\n## Detection Strategy\n\n1. **Name similarity matching** (fuzzy matching on project names)\n2. **README content comparison** (similar descriptions = potential duplicate)\n3. **File structure analysis** (similar file organization)\n4. **Code similarity** (identical or very similar code files)\n\n---\n\nEOF\n\necho \"Report file: $REPORT_FILE\"\n\n# Function to normalize project name for comparison\nnormalize_name() {\n    local name=\"$1\"\n    # Remove prefixes, convert to lowercase, remove hyphens/underscores\n    echo \"$name\" | \\\n        sed 's/^PRJ-[A-Z]*-[0-9]*-//gi' | \\\n        sed 's/^p[0-9]*-//gi' | \\\n        sed 's/^[0-9]*-//gi' | \\\n        tr '[:upper:]' '[:lower:]' | \\\n        tr '-_' ' '\n}\n\necho -e \"${YELLOW}Scanning current repository projects...${NC}\"\ncurrent_projects=()\nwhile IFS= read -r -d '' project_dir; do\n    project_name=$(basename \"$project_dir\")\n    current_projects+=(\"$project_dir:$project_name\")\ndone < <(find \"$CURRENT_PROJECTS\" -mindepth 1 -maxdepth 2 -type d \\( -name \"p[0-9]*\" -o -name \"PRJ-*\" -o -name \"[0-9]*-*\" \\) -print0 2>/dev/null)\n\necho \"Found ${#current_projects[@]} projects in current repository\"\n\n# If extraction directory exists, scan it too\nextracted_projects=()\nif [ -d \"$EXTRACT_BASE\" ]; then\n    echo -e \"${YELLOW}Scanning extracted archives...${NC}\"\n    while IFS= read -r -d '' project_dir; do\n        project_name=$(basename \"$project_dir\")\n        extracted_projects+=(\"$project_dir:$project_name\")\n    done < <(find \"$EXTRACT_BASE\" -type d \\( -name \"p[0-9]*\" -o -name \"PRJ-*\" -o -name \"[0-9]*-*\" \\) -print0 2>/dev/null)\n    echo \"Found ${#extracted_projects[@]} projects in extracted archives\"\nfi\n\n# Combine all projects\nall_projects=(\"${current_projects[@]}\" \"${extracted_projects[@]}\")\necho \"\"\necho \"Total projects to analyze: ${#all_projects[@]}\"\necho \"\"\n\n# Analysis\necho -e \"${BLUE}=== Analyzing for duplicates ===${NC}\" | tee -a \"$REPORT_FILE\"\necho \"\" | tee -a \"$REPORT_FILE\"\n\n# Create project catalog\ndeclare -A name_groups\n\nfor project_info in \"${all_projects[@]}\"; do\n    project_dir=\"${project_info%%:*}\"\n    project_name=\"${project_info##*:}\"\n    normalized=$(normalize_name \"$project_name\")\n\n    # Group by normalized name\n    if [ -n \"${name_groups[$normalized]}\" ]; then\n        name_groups[$normalized]=\"${name_groups[$normalized]}|$project_dir\"\n    else\n        name_groups[$normalized]=\"$project_dir\"\n    fi\ndone\n\n# Report grouped projects\necho \"## Potential Duplicates by Name Similarity\" >> \"$REPORT_FILE\"\necho \"\" >> \"$REPORT_FILE\"\n\nduplicate_groups=0\nfor normalized_name in \"${!name_groups[@]}\"; do\n    IFS='|' read -ra projects <<< \"${name_groups[$normalized_name]}\"\n\n    if [ ${#projects[@]} -gt 1 ]; then\n        ((duplicate_groups++))\n        echo -e \"${YELLOW}Duplicate group #$duplicate_groups: '$normalized_name'${NC}\"\n        echo \"### Group #$duplicate_groups: \\`$normalized_name\\`\" >> \"$REPORT_FILE\"\n        echo \"\" >> \"$REPORT_FILE\"\n        echo \"| Location | Full Name | Has README | File Count |\" >> \"$REPORT_FILE\"\n        echo \"|----------|-----------|------------|------------|\" >> \"$REPORT_FILE\"\n\n        for proj_dir in \"${projects[@]}\"; do\n            proj_name=$(basename \"$proj_dir\")\n            readme_exists=\"❌\"\n            if [ -f \"$proj_dir/README.md\" ]; then\n                readme_exists=\"✅\"\n            fi\n            file_count=$(find \"$proj_dir\" -type f 2>/dev/null | wc -l)\n            rel_path=$(echo \"$proj_dir\" | sed \"s|$REPO_ROOT/||\")\n\n            echo \"  - $rel_path ($file_count files, README: $readme_exists)\"\n            echo \"| \\`$rel_path\\` | $proj_name | $readme_exists | $file_count |\" >> \"$REPORT_FILE\"\n        done\n\n        echo \"\" >> \"$REPORT_FILE\"\n        echo \"\" >> \"$REPORT_FILE\"\n        echo \"\"\n    fi\ndone\n\nif [ $duplicate_groups -eq 0 ]; then\n    echo -e \"${GREEN}No obvious duplicates found by name matching${NC}\"\n    echo \"No duplicates detected by name similarity.\" >> \"$REPORT_FILE\"\nelse\n    echo -e \"${RED}Found $duplicate_groups potential duplicate groups${NC}\"\nfi\n\necho \"\" >> \"$REPORT_FILE\"\n\n# Summary statistics\necho \"## Summary Statistics\" >> \"$REPORT_FILE\"\necho \"\" >> \"$REPORT_FILE\"\necho \"- Total projects analyzed: ${#all_projects[@]}\" >> \"$REPORT_FILE\"\necho \"- Projects in current repository: ${#current_projects[@]}\" >> \"$REPORT_FILE\"\necho \"- Projects in extracted archives: ${#extracted_projects[@]}\" >> \"$REPORT_FILE\"\necho \"- Potential duplicate groups: $duplicate_groups\" >> \"$REPORT_FILE\"\necho \"\" >> \"$REPORT_FILE\"\n\n# Recommendations\necho \"## Recommendations\" >> \"$REPORT_FILE\"\necho \"\" >> \"$REPORT_FILE\"\necho \"1. **Review duplicate groups** - Manually inspect each group\" >> \"$REPORT_FILE\"\necho \"2. **Compare README content** - Most complete documentation prioritized\" >> \"$REPORT_FILE\"\necho \"3. **Check file counts** - More files usually = more complete\" >> \"$REPORT_FILE\"\necho \"4. **Use compare-versions.py** for detailed analysis\" >> \"$REPORT_FILE\"\necho \"5. **Follow merge plan** in STRUCTURE_ANALYSIS_AND_MERGE_PLAN.md\" >> \"$REPORT_FILE\"\necho \"\" >> \"$REPORT_FILE\"\n\necho \"\"\necho -e \"${GREEN}✓ Report generated: $REPORT_FILE${NC}\"\necho \"\"\necho \"Summary:\"\necho \"- Total projects: ${#all_projects[@]}\"\necho \"- Duplicate groups found: $duplicate_groups\"\n\nexit 0"
    }
  }
}
